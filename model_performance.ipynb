import pandas as pd
import time
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score
from sklearn.ensemble import RandomForestRegressor  # Regressor, not classifier
from sklearn.svm import SVR  # Support Vector Regressor
from sklearn.linear_model import LinearRegression  # Linear regression
from sklearn.neighbors import KNeighborsRegressor  # KNN for regression
from sklearn.tree import DecisionTreeRegressor  # Decision tree regressor
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# Read the dataset (adjust the path)
df = pd.read_csv('/Users/ameethaballa/Desktop/EPD_2021.csv')

# Data Preprocessing: Dropping unnecessary columns and handling missing values
X = df.drop(columns=['Day', 'UNE'])
y = df['UNE']

# Imputation of missing values
X_imputed = SimpleImputer(strategy='mean').fit_transform(X)
y_imputed = SimpleImputer(strategy='mean').fit_transform(y.values.reshape(-1, 1)).ravel()

# Split the dataset into training and testing
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_imputed, test_size=0.2, random_state=42)

# Models dictionary (using regressors now)
models = {
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Support Vector Machine": SVR(),
    "Linear Regression": LinearRegression(),
    "K-Nearest Neighbors": KNeighborsRegressor(n_neighbors=5),
    "Decision Tree": DecisionTreeRegressor(random_state=42)
}

performance = {}

# Loop over models, train, test, and store performance metrics
for name, model in models.items():
    start_train = time.time()
    model.fit(X_train, y_train)  # Train the model
    end_train = time.time()

    start_test = time.time()
    y_pred = model.predict(X_test)  # Make predictions
    end_test = time.time()

    # Calculate threshold using numpy's median function
    threshold = np.median(y_train)  # Use np.median() to find the threshold

    # Convert continuous predictions to binary (based on a threshold)
    y_test_class = (y_test >= threshold).astype(int)
    y_pred_class = (y_pred >= threshold).astype(int)

    # Calculate performance metrics
    performance[name] = {
        "Mean Absolute Error": mean_absolute_error(y_test, y_pred),
        "R-squared": r2_score(y_test, y_pred),
        "Accuracy": accuracy_score(y_test_class, y_pred_class),  # Calculate accuracy
        "Training Time (s)": end_train - start_train,
        "Testing Time (s)": end_test - start_test
    }

# Convert performance data to a DataFrame
performance_df = pd.DataFrame(performance).T
print(performance_df)

# Plotting: Visualize the performance comparisons
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
fig.suptitle("Model Performance Comparison", fontsize=16)

metrics = ["Mean Absolute Error", "R-squared", "Accuracy", "Training Time (s)", "Testing Time (s)"]
colors = ['b', 'g', 'r', 'c', 'm']

for i, metric in enumerate(metrics):
    ax = axes[i // 3, i % 3]
    performance_df[metric].plot(kind='bar', ax=ax, color=colors, alpha=0.7)
    ax.set_title(metric)
    ax.set_ylabel(metric)
    ax.set_xticklabels(performance_df.index, rotation=45)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Comparison bar for Performance Metrics (Mean Absolute Error, R-squared, Accuracy)
performance_df[["Mean Absolute Error", "R-squared", "Accuracy"]].plot(kind='bar', figsize=(12, 6), colormap='viridis', alpha=0.8)
plt.title("Model Performance Comparison")
plt.ylabel("Score")
plt.xticks(rotation=45)
plt.legend(loc='lower right')
plt.show()

# Plot for Training & Testing Time Comparison
performance_df[["Training Time (s)", "Testing Time (s)"]].plot(kind='line', marker='o', figsize=(12, 6), colormap='coolwarm')
plt.title("Training & Testing Time Comparison")
plt.ylabel("Time (seconds)")
plt.xticks(rotation=45)
plt.grid()
plt.show()

# Scatter plot for Mean Absolute Error vs R-squared
plt.figure(figsize=(8, 6))
plt.scatter(performance_df["Mean Absolute Error"], performance_df["R-squared"], c='blue', edgecolors='black')
plt.xlabel("Mean Absolute Error")
plt.ylabel("R-squared")
plt.title("Mean Absolute Error vs R-squared Comparison")
plt.grid(True)
plt.show()

# Boxplot for Distribution of Performance Metrics
plt.figure(figsize=(10, 6))
sns.boxplot(data=performance_df[["Mean Absolute Error", "R-squared", "Accuracy"]], palette="coolwarm")
plt.title("Distribution of Model Performance Metrics")
plt.grid()
plt.show()
